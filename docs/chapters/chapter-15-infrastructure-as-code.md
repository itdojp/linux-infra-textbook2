---
layout: book
order: 17
title: "ç¬¬15ç« ï¼šè‡ªå‹•åŒ–ã¸ã®é“ - Infrastructure as Code"
---

# ç¬¬15ç« ï¼šè‡ªå‹•åŒ–ã¸ã®é“ - Infrastructure as Code

## ğŸ“š ã“ã®ç« ã®å‰æçŸ¥è­˜
- âœ… **å¿…è¦**: ç¬¬12-14ç« ã®AWSã‚¯ãƒ©ã‚¦ãƒ‰æŠ€è¡“ã®ç†è§£
- âœ… **å¿…è¦**: YAMLã‚„JSONã®åŸºæœ¬çš„ãªèª­ã¿æ›¸ã
- âœ… **æ¨å¥¨**: Gitã®åŸºæœ¬æ“ä½œ
- âŒ **ä¸è¦**: é«˜åº¦ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¹ã‚­ãƒ«

## ğŸ¯ ã“ã®ç« ã®ç›®æ¨™
- Infrastructure as Codeï¼ˆIaCï¼‰ã®æ¦‚å¿µã¨ãƒ¡ãƒªãƒƒãƒˆã‚’ç†è§£ã™ã‚‹
- Terraformã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ãƒã‚¹ã‚¿ãƒ¼ã™ã‚‹
- ã‚³ãƒ¼ãƒ‰ã§ã‚¤ãƒ³ãƒ•ãƒ©ã‚’ç®¡ç†ã™ã‚‹ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’å­¦ã¶

## ğŸš€ ã“ã®ç« ã§ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨
- Terraformã§AWSãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚³ãƒ¼ãƒ‰ã§ç®¡ç†ã§ãã‚‹
- ã‚¤ãƒ³ãƒ•ãƒ©ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨å¤‰æ›´è¿½è·¡ãŒã§ãã‚‹
- ãƒãƒ¼ãƒ ã§ã®ã‚¤ãƒ³ãƒ•ãƒ©å…±æœ‰ã¨ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒã§ãã‚‹

## 15.1 ã¯ã˜ã‚ã«ï¼šæ‰‹ä½œæ¥­ã‹ã‚‰ã®è§£æ”¾

æ·±å¤œ3æ™‚ã€‚æ–°ã—ã„ã‚µãƒ¼ãƒãƒ¼ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒç”Ÿã˜ã¾ã—ãŸã€‚å¾“æ¥ãªã‚‰ï¼š

1. ç®¡ç†ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ãƒ­ã‚°ã‚¤ãƒ³
2. ã‚µãƒ¼ãƒãƒ¼ã®è¨­å®šã‚’ä¸€ã¤ãšã¤å…¥åŠ›
3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’æ‰‹å‹•ã§æ§‹æˆ
4. ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
5. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†
6. ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•

çœ ã„ç›®ã‚’ã“ã™ã‚ŠãªãŒã‚‰ã®ä½œæ¥­ã€‚ä¸€ã¤ã§ã‚‚é–“é•ãˆã‚Œã°ã€ã‚µãƒ¼ãƒ“ã‚¹ã«å½±éŸ¿ãŒå‡ºã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚

ã—ã‹ã—ä»Šã¯é•ã„ã¾ã™ã€‚

```bash
terraform apply
```

ãŸã£ãŸä¸€ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§ã€è¤‡é›‘ãªã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãŒæ­£ç¢ºã«ã€å†ç¾å¯èƒ½ãªå½¢ã§æ§‹ç¯‰ã•ã‚Œã‚‹ã€‚ã“ã‚ŒãŒInfrastructure as Codeï¼ˆIaCï¼‰ã®ä¸–ç•Œã§ã™ã€‚

## 15.2 æ‰‹ä½œæ¥­ã®é™ç•Œã¨äººçš„ãƒŸã‚¹ã®æ’é™¤

### æ‰‹ä½œæ¥­ã®å•é¡Œç‚¹

#### å®Ÿä¾‹ï¼šã‚ã‚‹ä¼æ¥­ã®æ‚²åŠ‡
```
2019å¹´æŸæ—¥ã€å¤§æ‰‹ä¼æ¥­ã®ã‚¤ãƒ³ãƒ•ãƒ©ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢Aã•ã‚“ã®ä½œæ¥­è¨˜éŒ²ï¼š

09:00 - æœ¬ç•ªã‚µãƒ¼ãƒãƒ¼#1ã®è¨­å®šå¤‰æ›´é–‹å§‹
09:30 - æœ¬ç•ªã‚µãƒ¼ãƒãƒ¼#2ã®è¨­å®šå¤‰æ›´é–‹å§‹
09:45 - æœ¬ç•ªã‚µãƒ¼ãƒãƒ¼#3ã®è¨­å®šå¤‰æ›´é–‹å§‹
        â†’ ã‚ã‚Œï¼Ÿ#2ã®è¨­å®šã€ä¸€ã¤æŠœã‘ã¦ãªã„ï¼Ÿ
10:00 - ã‚µãƒ¼ãƒ“ã‚¹éšœå®³ç™ºç”Ÿ
        â†’ #2ã ã‘è¨­å®šãŒç•°ãªã‚Šã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‹ã‚‰å¤–ã‚Œã‚‹
10:30 - åŸå› ç‰¹å®šã€æ‰‹å‹•ã§ä¿®æ­£
11:00 - ã‚µãƒ¼ãƒ“ã‚¹å¾©æ—§

æå¤±ï¼š1æ™‚é–“ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã€ä¿¡é ¼ã®å¤±å¢œ
```

### äººçš„ãƒŸã‚¹ã®åˆ†é¡ã¨å¯¾ç­–

#### 1. è¨­å®šãƒŸã‚¹
```yaml
# æ‰‹ä½œæ¥­ã§ã®å…¸å‹çš„ãªãƒŸã‚¹
server1: memory=8GB, cpu=4
server2: memory=8GB, cpu=4
server3: memory=8G, cpu=4  # å˜ä½ã®èª¤ã‚Šï¼

# IaCã§ã®é˜²æ­¢
variable "server_config" {
  type = object({
    memory = string
    cpu    = number
  })
  default = {
    memory = "8GB"
    cpu    = 4
  }
  
  validation {
    condition     = can(regex("^[0-9]+[GM]B$", var.server_config.memory))
    error_message = "Memory must be in format like '8GB' or '512MB'."
  }
}
```

#### 2. æ‰‹é †ã®æŠœã‘æ¼ã‚Œ
```bash
# æ‰‹ä½œæ¥­ã®æ‰‹é †æ›¸ï¼ˆäººé–“ã¯ãƒŸã‚¹ã‚’ã™ã‚‹ï¼‰
1. ã‚µãƒ¼ãƒãƒ¼ã‚’ä½œæˆ
2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—ã‚’è¨­å®š
3. ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
4. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†
5. ç›£è¦–è¨­å®šã‚’è¿½åŠ  â† ã‚ˆãå¿˜ã‚Œã‚‰ã‚Œã‚‹

# IaCã§ã¯ä¾å­˜é–¢ä¿‚ãŒæ˜ç¢º
resource "aws_instance" "web" {
  # ...
}

resource "aws_cloudwatch_metric_alarm" "cpu" {
  # EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«è‡ªå‹•çš„ã«ç´ä»˜ã‘ã‚‰ã‚Œã‚‹
  dimensions = {
    InstanceId = aws_instance.web.id
  }
}
```

#### 3. ç’°å¢ƒé–“ã®å·®ç•°
```hcl
# ç’°å¢ƒã”ã¨ã®è¨­å®šã‚’å¤‰æ•°ã§ç®¡ç†
variable "environment" {
  type = string
}

locals {
  instance_type = {
    dev  = "t3.micro"
    stg  = "t3.small"
    prod = "t3.large"
  }
}

resource "aws_instance" "app" {
  instance_type = local.instance_type[var.environment]
  # ç’°å¢ƒã«å¿œã˜ã¦è‡ªå‹•çš„ã«é©åˆ‡ãªã‚µã‚¤ã‚ºãŒé¸æŠã•ã‚Œã‚‹
}
```

## 15.3 å®£è¨€çš„è¨­å®šã¨å†ªç­‰æ€§

### å®£è¨€çš„ vs å‘½ä»¤çš„

#### å‘½ä»¤çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆå¾“æ¥ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰
```bash
# å‘½ä»¤çš„ï¼šã€Œã©ã†ã‚„ã£ã¦ã€ä½œã‚‹ã‹ã‚’è¨˜è¿°
#!/bin/bash
# ã‚µãƒ¼ãƒãƒ¼ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ãªã„
# 2å›å®Ÿè¡Œã™ã‚‹ã¨2å°ä½œã‚‰ã‚Œã‚‹ï¼
aws ec2 run-instances --instance-type t3.micro --count 1

# ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ 
# æ—¢ã«å­˜åœ¨ã—ã¦ã„ã¦ã‚‚ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ãªã—
iptables -A INPUT -p tcp --dport 80 -j ACCEPT
```

#### å®£è¨€çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆIaCï¼‰
```hcl
# å®£è¨€çš„ï¼šã€Œä½•ãŒã€æ¬²ã—ã„ã‹ã‚’è¨˜è¿°
resource "aws_instance" "web" {
  instance_type = "t3.micro"
  count         = 1
  
  # ã‚¿ã‚°ã§è­˜åˆ¥
  tags = {
    Name = "WebServer"
  }
}

# ä½•åº¦å®Ÿè¡Œã—ã¦ã‚‚çµæœã¯åŒã˜ï¼ˆå†ªç­‰æ€§ï¼‰
# - å­˜åœ¨ã—ãªã‘ã‚Œã°ä½œæˆ
# - å­˜åœ¨ã™ã‚Œã°ä½•ã‚‚ã—ãªã„
# - è¨­å®šãŒé•ãˆã°ä¿®æ­£
```

### å†ªç­‰æ€§ã®é‡è¦æ€§

#### å†ªç­‰æ€§ã¨ã¯
```
f(x) = f(f(x)) = f(f(f(x))) = ...

ä½•åº¦å®Ÿè¡Œã—ã¦ã‚‚åŒã˜çµæœã«ãªã‚‹æ€§è³ª
```

#### å®Ÿä¾‹ã§ç†è§£ã™ã‚‹å†ªç­‰æ€§
```python
# å†ªç­‰ã§ãªã„æ“ä½œ
counter += 1  # å®Ÿè¡Œã™ã‚‹ãŸã³ã«å€¤ãŒå¤‰ã‚ã‚‹

# å†ªç­‰ãªæ“ä½œ
counter = 10  # ä½•åº¦å®Ÿè¡Œã—ã¦ã‚‚ counter ã¯ 10

# ã‚¤ãƒ³ãƒ•ãƒ©ã§ã®å†ªç­‰æ€§
desired_state = {
    'servers': 3,
    'load_balancer': 1,
    'database': 'mysql'
}

current_state = get_current_infrastructure()
if current_state != desired_state:
    apply_changes(desired_state)
# æ—¢ã«æœ›ã‚€çŠ¶æ…‹ãªã‚‰ä½•ã‚‚ã—ãªã„
```

### çŠ¶æ…‹ç®¡ç†ã®ä»•çµ„ã¿

#### Terraformã®çŠ¶æ…‹ç®¡ç†
```hcl
# terraform.tfstate - ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¨˜éŒ²
{
  "version": 4,
  "terraform_version": "1.0.0",
  "resources": [
    {
      "mode": "managed",
      "type": "aws_instance",
      "name": "web",
      "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
      "instances": [
        {
          "attributes": {
            "id": "i-1234567890abcdef0",
            "instance_type": "t3.micro",
            "public_ip": "203.0.113.10",
            "tags": {
              "Name": "WebServer"
            }
          }
        }
      ]
    }
  ]
}
```

#### çŠ¶æ…‹ã®åŒæœŸ
```bash
# å®Ÿéš›ã®ã‚¤ãƒ³ãƒ•ãƒ©ã¨çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã®å·®åˆ†ã‚’ç¢ºèª
terraform plan

# å·®åˆ†ãŒã‚ã‚Œã°è¡¨ç¤ºã•ã‚Œã‚‹
# ~ resource "aws_instance" "web" {
#     ~ instance_type = "t3.micro" -> "t3.small"
#   }

# å·®åˆ†ã‚’é©ç”¨
terraform apply
```

## 15.4 å†ç¾å¯èƒ½ã§ç›£æŸ»å¯èƒ½ãªã‚¤ãƒ³ãƒ•ãƒ©

### ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ã®çµ±åˆ

#### Gitã«ã‚ˆã‚‹ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ãƒ¼ãƒ‰ã®ç®¡ç†
```bash
# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
infrastructure/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â””â”€â”€ production/
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â””â”€â”€ terraform.tfvars
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ vpc/
â”‚   â”œâ”€â”€ compute/
â”‚   â””â”€â”€ database/
â””â”€â”€ .gitignore

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
git add .
git commit -m "Add auto-scaling configuration for production"
git push origin main
```

#### ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹å“è³ªä¿è¨¼
```yaml
# .github/workflows/terraform-pr.yml
name: Terraform Pull Request Check

on:
  pull_request:
    paths:
      - 'infrastructure/**'

jobs:
  terraform:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
      
      - name: Terraform Format Check
        run: terraform fmt -check -recursive
      
      - name: Terraform Init
        run: terraform init
      
      - name: Terraform Validate
        run: terraform validate
      
      - name: Terraform Plan
        run: terraform plan -out=tfplan
      
      - name: Post Plan to PR
        uses: actions/github-script@v6
        with:
          script: |
            const plan = require('fs').readFileSync('tfplan.txt', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Terraform Plan\n\`\`\`\n${plan}\n\`\`\``
            });
```

### ç›£æŸ»è¨¼è·¡ï¼ˆAudit Trailï¼‰

#### å¤‰æ›´å±¥æ­´ã®å®Œå…¨ãªè¨˜éŒ²
```bash
# ã™ã¹ã¦ã®å¤‰æ›´ãŒGitã«è¨˜éŒ²ã•ã‚Œã‚‹
git log --oneline infrastructure/

# å‡ºåŠ›ä¾‹ï¼š
# a1b2c3d Add ALB for high availability
# d4e5f6g Increase instance size for production
# g7h8i9j Add CloudWatch alarms
# j1k2l3m Initial infrastructure setup

# ç‰¹å®šã®å¤‰æ›´ã®è©³ç´°ã‚’ç¢ºèª
git show a1b2c3d

# èª°ãŒã€ã„ã¤ã€ä½•ã‚’ã€ãªãœå¤‰æ›´ã—ãŸã‹ãŒæ˜ç¢º
```

#### ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹å¯¾å¿œ
```hcl
# ãƒãƒªã‚·ãƒ¼ã®å¼·åˆ¶
resource "aws_s3_bucket" "data" {
  bucket = "company-sensitive-data"
  
  # æš—å·åŒ–ã‚’å¼·åˆ¶
  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = "AES256"
      }
    }
  }
  
  # ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
  versioning {
    enabled = true
  }
  
  # ãƒ­ã‚®ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
  logging {
    target_bucket = aws_s3_bucket.logs.id
    target_prefix = "s3-access-logs/"
  }
  
  # ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’ãƒ–ãƒ­ãƒƒã‚¯
  public_access_block {
    block_public_acls       = true
    block_public_policy     = true
    ignore_public_acls      = true
    restrict_public_buckets = true
  }
  
  # ã‚¿ã‚°ã«ã‚ˆã‚‹ç®¡ç†
  tags = {
    Environment = var.environment
    Compliance  = "GDPR"
    Owner       = "DataTeam"
    CreatedBy   = "Terraform"
  }
}
```

### ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã¨ä¿®æ­£

#### æ‰‹å‹•å¤‰æ›´ã®æ¤œå‡º
```bash
# å®Ÿéš›ã®ã‚¤ãƒ³ãƒ•ãƒ©ã¨ã‚³ãƒ¼ãƒ‰ã®å·®ç•°ã‚’æ¤œå‡º
terraform plan -refresh-only

# ãƒ‰ãƒªãƒ•ãƒˆãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®å‡ºåŠ›ä¾‹ï¼š
# Note: Objects have changed outside of Terraform
# 
# aws_security_group.web has been changed:
#   ~ ingress = [
#       + {
#           + from_port   = 8080
#           + to_port     = 8080
#           + protocol    = "tcp"
#           + cidr_blocks = ["0.0.0.0/0"]
#         },
#     ]

# ãƒ‰ãƒªãƒ•ãƒˆã®ä¿®æ­£ï¼ˆã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã‚‹ï¼‰
terraform apply -refresh-only
```

## 15.5 æ¼”ç¿’ï¼šæ‰‹ä½œæ¥­ã‹ã‚‰è‡ªå‹•åŒ–ã¸ã®æ®µéšçš„ç§»è¡Œ

### æ¼”ç¿’1ï¼šæ—¢å­˜ã‚¤ãƒ³ãƒ•ãƒ©ã®ã‚³ãƒ¼ãƒ‰åŒ–

```bash
# import_existing_infra.sh
cat > import_existing_infra.sh << 'EOF'
#!/bin/bash

echo "=== Importing Existing Infrastructure to Terraform ==="

# 1. æ—¢å­˜ãƒªã‚½ãƒ¼ã‚¹ã®èª¿æŸ»
echo "Discovering existing resources..."

# EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä¸€è¦§å–å¾—
instances=$(aws ec2 describe-instances \
    --query 'Reservations[*].Instances[*].[InstanceId,Tags[?Key==`Name`].Value|[0]]' \
    --output text)

# 2. Terraformã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆ
cat > main.tf << 'TF'
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"
    }
  }
}

provider "aws" {
  region = "ap-northeast-1"
}
TF

# 3. å„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
while IFS=$'\t' read -r instance_id name; do
    echo "Importing instance: $instance_id ($name)"
    
    # Terraformãƒªã‚½ãƒ¼ã‚¹å®šç¾©ã‚’è¿½åŠ 
    cat >> main.tf << TF

resource "aws_instance" "$name" {
  # Imported resource
}
TF
    
    # å®Ÿéš›ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    terraform import "aws_instance.$name" "$instance_id"
done <<< "$instances"

# 4. è¨­å®šã®è©³ç´°ã‚’å–å¾—ã—ã¦æ›´æ–°
echo "Updating resource configurations..."
terraform plan
EOF

chmod +x import_existing_infra.sh
```

### æ¼”ç¿’2ï¼šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã«ã‚ˆã‚‹å†åˆ©ç”¨æ€§å‘ä¸Š

```hcl
# modules/web-server/main.tf
variable "instance_count" {
  description = "Number of instances"
  type        = number
  default     = 1
}

variable "instance_type" {
  description = "EC2 instance type"
  type        = string
  default     = "t3.micro"
}

variable "environment" {
  description = "Environment name"
  type        = string
}

# Launch Template
resource "aws_launch_template" "web" {
  name_prefix   = "${var.environment}-web-"
  image_id      = data.aws_ami.amazon_linux_2.id
  instance_type = var.instance_type
  
  vpc_security_group_ids = [aws_security_group.web.id]
  
  user_data = base64encode(<<-EOF
    #!/bin/bash
    yum update -y
    yum install -y nginx
    systemctl start nginx
    systemctl enable nginx
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒšãƒ¼ã‚¸
    cat > /usr/share/nginx/html/index.html <<-HTML
    <h1>Welcome to ${var.environment} environment</h1>
    <p>Server: $(hostname)</p>
    <p>Instance Type: ${var.instance_type}</p>
    HTML
  EOF
  )
  
  tag_specifications {
    resource_type = "instance"
    tags = {
      Name        = "${var.environment}-web-server"
      Environment = var.environment
      ManagedBy   = "Terraform"
    }
  }
}

# Auto Scaling Group
resource "aws_autoscaling_group" "web" {
  name               = "${var.environment}-web-asg"
  vpc_zone_identifier = var.subnet_ids
  target_group_arns  = [aws_lb_target_group.web.arn]
  health_check_type  = "ELB"
  health_check_grace_period = 300
  
  min_size         = var.instance_count
  max_size         = var.instance_count * 3
  desired_capacity = var.instance_count
  
  launch_template {
    id      = aws_launch_template.web.id
    version = "$Latest"
  }
  
  tag {
    key                 = "Name"
    value               = "${var.environment}-web-asg"
    propagate_at_launch = false
  }
}

# Application Load Balancer
resource "aws_lb" "web" {
  name               = "${var.environment}-web-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = var.public_subnet_ids
  
  enable_deletion_protection = var.environment == "production"
  
  tags = {
    Name        = "${var.environment}-web-alb"
    Environment = var.environment
  }
}

# Output
output "load_balancer_dns" {
  description = "DNS name of the load balancer"
  value       = aws_lb.web.dns_name
}

output "autoscaling_group_name" {
  description = "Name of the Auto Scaling group"
  value       = aws_autoscaling_group.web.name
}
```

### æ¼”ç¿’3ï¼šCI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰

```yaml
# .gitlab-ci.yml - GitLab CI/CDè¨­å®š
stages:
  - validate
  - plan
  - apply
  - destroy

variables:
  TF_ROOT: ${CI_PROJECT_DIR}/infrastructure
  TF_STATE_NAME: ${CI_PROJECT_NAME}-${CI_ENVIRONMENT_NAME}

before_script:
  - cd ${TF_ROOT}
  - terraform init
    -backend-config="bucket=terraform-state-bucket"
    -backend-config="key=${TF_STATE_NAME}/terraform.tfstate"
    -backend-config="region=ap-northeast-1"

validate:
  stage: validate
  script:
    - terraform fmt -check -recursive
    - terraform validate
    - tflint
    - checkov -d . --framework terraform
  rules:
    - if: $CI_MERGE_REQUEST_ID

plan:development:
  stage: plan
  script:
    - terraform workspace select development || terraform workspace new development
    - terraform plan -var-file=environments/development.tfvars -out=plan.tfplan
    - terraform show -no-color plan.tfplan > plan.txt
  artifacts:
    paths:
      - ${TF_ROOT}/plan.tfplan
      - ${TF_ROOT}/plan.txt
    expire_in: 7 days
  environment:
    name: development
  rules:
    - if: $CI_COMMIT_BRANCH == "develop"

apply:development:
  stage: apply
  script:
    - terraform workspace select development
    - terraform apply -auto-approve plan.tfplan
  dependencies:
    - plan:development
  environment:
    name: development
    on_stop: destroy:development
  rules:
    - if: $CI_COMMIT_BRANCH == "develop"
      when: manual

plan:production:
  stage: plan
  script:
    - terraform workspace select production || terraform workspace new production
    - terraform plan -var-file=environments/production.tfvars -out=plan.tfplan
    - terraform show -no-color plan.tfplan > plan.txt
  artifacts:
    paths:
      - ${TF_ROOT}/plan.tfplan
      - ${TF_ROOT}/plan.txt
    expire_in: 7 days
  environment:
    name: production
  rules:
    - if: $CI_COMMIT_BRANCH == "main"

apply:production:
  stage: apply
  script:
    - terraform workspace select production
    - terraform apply -auto-approve plan.tfplan
    # é©ç”¨å¾Œã®æ¤œè¨¼
    - ./scripts/validate_deployment.sh
  dependencies:
    - plan:production
  environment:
    name: production
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
      when: manual
  only:
    - main

destroy:development:
  stage: destroy
  script:
    - terraform workspace select development
    - terraform destroy -auto-approve -var-file=environments/development.tfvars
  environment:
    name: development
    action: stop
  rules:
    - if: $CI_COMMIT_BRANCH == "develop"
      when: manual
```

### æ¼”ç¿’4ï¼šãƒãƒªã‚·ãƒ¼ã‚¢ã‚ºã‚³ãƒ¼ãƒ‰

```hcl
# policy.sentinel - Sentinelãƒãƒªã‚·ãƒ¼
import "tfplan/v2" as tfplan
import "tfconfig/v2" as tfconfig

# ãƒãƒªã‚·ãƒ¼1: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã®åˆ¶é™
instance_type_allowed = rule {
    all tfplan.resource_changes as _, rc {
        rc.type is not "aws_instance" or
        rc.change.after.instance_type in [
            "t3.micro",
            "t3.small",
            "t3.medium",
            "m5.large",
            "m5.xlarge"
        ]
    }
}

# ãƒãƒªã‚·ãƒ¼2: å¿…é ˆã‚¿ã‚°ã®ç¢ºèª
mandatory_tags = rule {
    all tfplan.resource_changes as _, rc {
        rc.mode is not "managed" or
        rc.change.after.tags is null or
        all [
            "Environment",
            "Owner",
            "CostCenter",
            "Project"
        ] as required_tag {
            required_tag in keys(rc.change.after.tags)
        }
    }
}

# ãƒãƒªã‚·ãƒ¼3: æš—å·åŒ–ã®å¼·åˆ¶
encryption_required = rule {
    all tfplan.resource_changes as _, rc {
        rc.type is not "aws_s3_bucket" or
        rc.change.after.server_side_encryption_configuration is not null
    }
}

# ãƒãƒªã‚·ãƒ¼4: ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã®ç¦æ­¢
no_public_access = rule {
    all tfplan.resource_changes as _, rc {
        rc.type is not "aws_s3_bucket" or
        (rc.change.after.acl is "private" and
         rc.change.after.public_access_block is not null and
         rc.change.after.public_access_block[0].block_public_acls is true)
    }
}

# ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ«
main = rule {
    instance_type_allowed and
    mandatory_tags and
    encryption_required and
    no_public_access
}
```

### æ¼”ç¿’5ï¼šç½å®³å¾©æ—§ã®è‡ªå‹•åŒ–

```hcl
# disaster_recovery.tf - ç½å®³å¾©æ—§ã®è‡ªå‹•åŒ–
module "primary_region" {
  source = "./modules/regional-infrastructure"
  
  region      = "ap-northeast-1"
  environment = var.environment
  vpc_cidr    = "10.0.0.0/16"
  
  enable_backup = true
  backup_retention_days = 30
}

module "dr_region" {
  source = "./modules/regional-infrastructure"
  
  region      = "ap-southeast-1"
  environment = "${var.environment}-dr"
  vpc_cidr    = "10.1.0.0/16"
  
  # DRãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¯æœ€å°æ§‹æˆ
  instance_count = var.dr_mode ? var.instance_count : 0
  instance_type  = var.dr_mode ? var.instance_type : "t3.micro"
}

# ã‚¯ãƒ­ã‚¹ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
resource "aws_s3_bucket_replication_configuration" "dr" {
  role   = aws_iam_role.replication.arn
  bucket = module.primary_region.s3_bucket_id
  
  rule {
    id     = "dr-replication"
    status = "Enabled"
    
    destination {
      bucket        = module.dr_region.s3_bucket_arn
      storage_class = "STANDARD_IA"
    }
  }
}

# RDSã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
resource "aws_db_instance" "primary" {
  identifier = "${var.environment}-database"
  
  # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ã®å¾©å…ƒã‚’ã‚µãƒãƒ¼ãƒˆ
  snapshot_identifier = var.restore_from_snapshot
  
  # è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
  backup_retention_period = 7
  backup_window          = "03:00-04:00"
  
  # æœ€çµ‚ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã®ä½œæˆ
  skip_final_snapshot       = false
  final_snapshot_identifier = "${var.environment}-database-final-${formatdate("YYYY-MM-DD-hhmm", timestamp())}"
}

# DRåˆ‡ã‚Šæ›¿ãˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
resource "null_resource" "dr_failover_script" {
  provisioner "local-exec" {
    command = <<-EOT
      cat > failover_to_dr.sh << 'EOF'
      #!/bin/bash
      echo "Starting failover to DR region..."
      
      # 1. Route 53ã®åˆ‡ã‚Šæ›¿ãˆ
      aws route53 change-resource-record-sets \
        --hosted-zone-id ${aws_route53_zone.main.id} \
        --change-batch '{
          "Changes": [{
            "Action": "UPSERT",
            "ResourceRecordSet": {
              "Name": "${var.domain_name}",
              "Type": "A",
              "AliasTarget": {
                "HostedZoneId": "${module.dr_region.alb_zone_id}",
                "DNSName": "${module.dr_region.alb_dns_name}",
                "EvaluateTargetHealth": true
              }
            }
          }]
        }'
      
      # 2. DRã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®èµ·å‹•
      terraform apply -var="dr_mode=true" -auto-approve
      
      echo "Failover completed!"
      EOF
      
      chmod +x failover_to_dr.sh
    EOT
  }
}

# ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ
resource "aws_cloudwatch_metric_alarm" "dr_health" {
  alarm_name          = "${var.environment}-dr-health"
  comparison_operator = "LessThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "HealthyHostCount"
  namespace           = "AWS/ApplicationELB"
  period              = "60"
  statistic           = "Average"
  threshold           = "1"
  alarm_description   = "This metric monitors DR region health"
  
  dimensions = {
    TargetGroup  = module.dr_region.target_group_arn_suffix
    LoadBalancer = module.dr_region.alb_arn_suffix
  }
  
  alarm_actions = [aws_sns_topic.alerts.arn]
}
```

## 15.6 IaCã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### ã‚³ãƒ¼ãƒ‰æ§‹é€ ã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­è¨ˆ

```bash
# æ¨å¥¨ã•ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
.
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ backend.tf
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â”‚   â””â”€â”€ variables.tf
â”‚   â”œâ”€â”€ staging/
â”‚   â””â”€â”€ production/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ networking/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ compute/
â”‚   â”œâ”€â”€ database/
â”‚   â””â”€â”€ monitoring/
â”œâ”€â”€ policies/
â”‚   â”œâ”€â”€ security.sentinel
â”‚   â””â”€â”€ cost.sentinel
â””â”€â”€ scripts/
    â”œâ”€â”€ setup.sh
    â””â”€â”€ validate.sh
```

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

```hcl
# secrets.tf - ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†
# 1. ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
variable "db_password" {
  description = "Database password"
  type        = string
  sensitive   = true
}

# 2. AWS Secrets Managerã®ä½¿ç”¨
data "aws_secretsmanager_secret_version" "db_password" {
  secret_id = "rds/production/password"
}

# 3. æš—å·åŒ–ã•ã‚ŒãŸtfvarsãƒ•ã‚¡ã‚¤ãƒ«
# terraform.tfvars.encryptedï¼ˆgit-cryptã§æš—å·åŒ–ï¼‰
db_password = "encrypted_value_here"

# 4. ãƒªã‚½ãƒ¼ã‚¹ã§ã®ä½¿ç”¨
resource "aws_db_instance" "main" {
  password = var.db_password  # ã¾ãŸã¯ data.aws_secretsmanager_secret_version.db_password.secret_string
}

# 5. å‡ºåŠ›æ™‚ã®ä¿è­·
output "db_endpoint" {
  value       = aws_db_instance.main.endpoint
  description = "Database endpoint"
}

output "db_password" {
  value       = var.db_password
  description = "Database password"
  sensitive   = true  # terraformã®å‡ºåŠ›ã§è¡¨ç¤ºã•ã‚Œãªã„
}
```

### ãƒ†ã‚¹ãƒˆã®è‡ªå‹•åŒ–

```go
// terraform_test.go - Terratest ã«ã‚ˆã‚‹è‡ªå‹•ãƒ†ã‚¹ãƒˆ
package test

import (
    "testing"
    "time"
    
    "github.com/gruntwork-io/terratest/modules/terraform"
    "github.com/gruntwork-io/terratest/modules/aws"
    "github.com/stretchr/testify/assert"
)

func TestWebServerModule(t *testing.T) {
    t.Parallel()
    
    // Terraform ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è¨­å®š
    terraformOptions := &terraform.Options{
        TerraformDir: "../modules/web-server",
        
        Vars: map[string]interface{}{
            "environment":    "test",
            "instance_count": 2,
            "instance_type":  "t3.micro",
        },
    }
    
    // ãƒ†ã‚¹ãƒˆçµ‚äº†æ™‚ã«ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤
    defer terraform.Destroy(t, terraformOptions)
    
    // Terraform init ã¨ apply
    terraform.InitAndApply(t, terraformOptions)
    
    // ALBã®DNSåã‚’å–å¾—
    albDNS := terraform.Output(t, terraformOptions, "load_balancer_dns")
    
    // ALBãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèª
    url := fmt.Sprintf("http://%s", albDNS)
    expectedStatus := 200
    maxRetries := 30
    timeBetweenRetries := 10 * time.Second
    
    http_helper.HttpGetWithRetryWithCustomValidation(
        t,
        url,
        nil,
        maxRetries,
        timeBetweenRetries,
        func(status int, body string) bool {
            return status == expectedStatus
        },
    )
    
    // Auto Scaling Groupã®ç¢ºèª
    asgName := terraform.Output(t, terraformOptions, "autoscaling_group_name")
    asg := aws.GetAutoScalingGroup(t, asgName, "ap-northeast-1")
    
    assert.Equal(t, int64(2), *asg.DesiredCapacity)
    assert.Equal(t, int64(2), *asg.MinSize)
    assert.Equal(t, int64(6), *asg.MaxSize)
}
```

### ã‚³ã‚¹ãƒˆæœ€é©åŒ–

```hcl
# cost_optimization.tf
# 1. é©åˆ‡ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã®é¸æŠ
locals {
  # ç’°å¢ƒã«å¿œã˜ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—
  instance_types = {
    dev  = "t3.micro"     # $0.0104/hour
    stg  = "t3.small"     # $0.0208/hour
    prod = "m5.large"     # $0.096/hour
  }
}

# 2. ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹æœ€é©åŒ–
resource "aws_autoscaling_schedule" "scale_down_nights" {
  scheduled_action_name  = "scale-down-nights"
  autoscaling_group_name = aws_autoscaling_group.web.name
  
  # å¤œé–“ã¯æœ€å°æ§‹æˆã«
  min_size         = 1
  max_size         = 3
  desired_capacity = 1
  
  # æ¯æ—¥19:00ã«å®Ÿè¡Œï¼ˆJSTï¼‰
  recurrence = "0 10 * * *"  # UTC
}

resource "aws_autoscaling_schedule" "scale_up_mornings" {
  scheduled_action_name  = "scale-up-mornings"
  autoscaling_group_name = aws_autoscaling_group.web.name
  
  # æœã¯é€šå¸¸æ§‹æˆã«
  min_size         = 2
  max_size         = 10
  desired_capacity = 3
  
  # æ¯æ—¥8:00ã«å®Ÿè¡Œï¼ˆJSTï¼‰
  recurrence = "0 23 * * *"  # UTC
}

# 3. ã‚¹ãƒãƒƒãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®æ´»ç”¨
resource "aws_autoscaling_group" "spot" {
  mixed_instances_policy {
    launch_template {
      launch_template_specification {
        launch_template_id = aws_launch_template.web.id
      }
      
      override {
        instance_type = "t3.medium"
      }
      
      override {
        instance_type = "t3a.medium"  # AMDç‰ˆ
      }
    }
    
    instances_distribution {
      on_demand_percentage_above_base_capacity = 0
      spot_allocation_strategy                 = "lowest-price"
      spot_instance_pools                      = 2
    }
  }
}

# 4. ã‚³ã‚¹ãƒˆã‚¢ãƒ©ãƒ¼ãƒˆ
resource "aws_budgets_budget" "monthly" {
  name              = "${var.environment}-monthly-budget"
  budget_type       = "COST"
  limit_amount      = var.monthly_budget_limit
  limit_unit        = "USD"
  time_unit         = "MONTHLY"
  
  notification {
    comparison_operator        = "GREATER_THAN"
    threshold                 = 80
    threshold_type            = "PERCENTAGE"
    notification_type         = "FORECASTED"
    subscriber_email_addresses = [var.finance_email]
  }
}
```

## 15.7 ã¾ã¨ã‚ï¼šã‚³ãƒ¼ãƒ‰ãŒã‚¤ãƒ³ãƒ•ãƒ©ã«ãªã‚‹æ™‚ä»£

### Infrastructure as CodeãŒã‚‚ãŸã‚‰ã—ãŸé©å‘½

æœ¬æ›¸ã®æœ€çµ‚ç« ã§å­¦ã‚“ã IaCã¯ã€ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†ã«ä»¥ä¸‹ã®é©å‘½ã‚’ã‚‚ãŸã‚‰ã—ã¾ã—ãŸï¼š

1. **å†ç¾æ€§**ï¼šåŒã˜ã‚³ãƒ¼ãƒ‰ã‹ã‚‰åŒã˜ã‚¤ãƒ³ãƒ•ãƒ©ãŒç”Ÿæˆã•ã‚Œã‚‹
2. **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†**ï¼šã‚¤ãƒ³ãƒ•ãƒ©ã®å¤‰æ›´å±¥æ­´ãŒè¿½è·¡å¯èƒ½
3. **å”åƒä½œæ¥­**ï¼šã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹å“è³ªå‘ä¸Š
4. **è‡ªå‹•åŒ–**ï¼šäººçš„ãƒŸã‚¹ã®æ’é™¤ã¨åŠ¹ç‡åŒ–
5. **ã‚¹ã‚±ãƒ¼ãƒ«**ï¼š1å°ã§ã‚‚1000å°ã§ã‚‚åŒã˜åŠ´åŠ›

### æ‰‹ä½œæ¥­ã‹ã‚‰è‡ªå‹•åŒ–ã¸ã®æ—…

```
1990å¹´ä»£ï¼šç‰©ç†ã‚µãƒ¼ãƒãƒ¼ã®æ‰‹å‹•è¨­å®š
    â†“
2000å¹´ä»£ï¼šè¨­å®šç®¡ç†ãƒ„ãƒ¼ãƒ«ï¼ˆPuppetã€Chefï¼‰
    â†“
2010å¹´ä»£ï¼šã‚¯ãƒ©ã‚¦ãƒ‰ã¨IaCï¼ˆTerraformã€CloudFormationï¼‰
    â†“
2020å¹´ä»£ï¼šGitOpsã€Policy as Code
    â†“
æœªæ¥ï¼šAIé§†å‹•ã®è‡ªå¾‹çš„ã‚¤ãƒ³ãƒ•ãƒ©ï¼Ÿ
```

### ã‚¤ãƒ³ãƒ•ãƒ©ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®æ–°ã—ã„å½¹å‰²

ã‚‚ã¯ã‚„ã‚¤ãƒ³ãƒ•ãƒ©ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯ã€ã‚µãƒ¼ãƒãƒ¼ãƒ©ãƒƒã‚¯ã®å‰ã§ä½œæ¥­ã™ã‚‹äººã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

ç¾ä»£ã®ã‚¤ãƒ³ãƒ•ãƒ©ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯ï¼š
- **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ**ï¼šã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã‚’è¨­è¨ˆã™ã‚‹
- **ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼**ï¼šã‚¤ãƒ³ãƒ•ãƒ©ã‚’ã‚³ãƒ¼ãƒ‰ã§è¡¨ç¾ã™ã‚‹
- **SRE**ï¼šä¿¡é ¼æ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¿½æ±‚ã™ã‚‹
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢**ï¼šè„…å¨ã‹ã‚‰å®ˆã‚‹
- **ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢**ï¼šåŠ¹ç‡çš„ãªé‹ç”¨ã‚’å®Ÿç¾ã™ã‚‹

### æœ¬æ›¸ã‚’çµ‚ãˆã¦

15ç« ã«ã‚ãŸã‚‹é•·ã„æ—…ã€ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚

Linuxã®åŸºç¤ã‹ã‚‰å§‹ã¾ã‚Šã€ã‚³ãƒ³ãƒ†ãƒŠã€ã‚¯ãƒ©ã‚¦ãƒ‰ã€ãã—ã¦Infrastructure as Codeã¾ã§ã€ç¾ä»£ã®ã‚¤ãƒ³ãƒ•ãƒ©æŠ€è¡“ã®å…¨ä½“åƒã‚’å­¦ã‚“ã§ãã¾ã—ãŸã€‚

ã—ã‹ã—ã€ã“ã‚Œã¯çµ‚ã‚ã‚Šã§ã¯ãªãå§‹ã¾ã‚Šã§ã™ã€‚æŠ€è¡“ã¯æ—¥ã€…é€²åŒ–ã—ã€æ–°ã—ã„ãƒ„ãƒ¼ãƒ«ã‚„ãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãŒç”Ÿã¾ã‚Œã¦ã„ã¾ã™ã€‚

æœ¬æ›¸ã§å­¦ã‚“ã ã€Œãªãœã€ã®è¦–ç‚¹ã‚’æŒã¡ç¶šã‘ã‚‹ã“ã¨ã§ã€æ–°ã—ã„æŠ€è¡“ã«ã‚‚å¯¾å¿œã§ãã‚‹ã¯ãšã§ã™ã€‚

**æœ€å¾Œã«**

```bash
#!/bin/bash
echo "Congratulations! You are now an Infrastructure Engineer."
echo "May your servers be stable and your deployments be smooth."
echo "Happy coding!"
```

ã‚¤ãƒ³ãƒ•ãƒ©ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ã—ã¦ã®ç´ æ™´ã‚‰ã—ã„ã‚­ãƒ£ãƒªã‚¢ã‚’æ­©ã¾ã‚Œã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™ã€‚